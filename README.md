# ğŸ® Gesture Game Controller UI

A cross-platform **desktop application** that lets users control browser games  
(**Subway Surfers** / **Temple Run 2**) using **hand gestures** detected from a webcam.

The project uses:
- ğŸ§  **MediaPipe Gesture Recognizer (Tasks API)** for accurate gesture detection
- ğŸ–¥ **PySide6 (Qt)** for a modern desktop launcher UI
- ğŸ® **pynput** to send keyboard input to games
- ğŸ“¦ **PyInstaller** to package the app for **macOS** and **Windows**

---

## âœ¨ Features

### ğŸ§­ Gesture-controlled launcher
You can navigate the launcher **without mouse or keyboard**:
- ğŸ‘Š **Closed_Fist** â†’ Move/hover through buttons
- ğŸ‘ **Thumb_Up** â†’ Select / Click the hovered button

### ğŸ® Game control (background)
When a game is selected:
1. The game opens in your browser
2. Gesture recognition runs **in the background**
3. Gestures are translated into keyboard inputs for the game

### ğŸ§ª Test mode
A camera window for testing:
- live gesture name + confidence
- FPS and latency
- hand skeleton visualization

---

## ğŸ§  Gesture mappings

### ğŸ® Game gestures â†’ actions

| Gesture (MediaPipe label) | Action | Meaning |
|---------------------------|--------|--------|
| âœŒï¸ Victory                | LEFT   | Move left |
| ğŸ¤Ÿ ILoveYou               | RIGHT  | Move right |
| â˜ï¸ Pointing_Up            | JUMP   | Jump |
| âœŠ Closed_Fist             | DUCK   | Duck / Roll |
| ğŸ‘ Thumb_Up               | SPACE  | Space key |

### ğŸ§­ Launcher gestures â†’ UI navigation

| Gesture | Action |
|-------|--------|
| ğŸ‘Š Closed_Fist | Move selection |
| ğŸ‘ Thumb_Up | Select / Click |

---

## ğŸ—‚ Project structure

```
GestureControlGameUI/
â”œâ”€ app/
â”‚  â”œâ”€ __init__.py
â”‚  â”œâ”€ gesture_test.py          # Test mode with live camera preview
â”‚  â”œâ”€ run_launcher.py          # Main entry point
â”‚  â”œâ”€ assets/
â”‚  â”‚  â””â”€ gesture_recognizer.task   # Pre-trained MediaPipe model
â”‚  â”œâ”€ core/
â”‚  â”‚  â”œâ”€ __init__.py
â”‚  â”‚  â”œâ”€ background_runner.py      # Runs gesture recognition in background
â”‚  â”‚  â”œâ”€ controller.py             # Keyboard input via pynput
â”‚  â”‚  â”œâ”€ gesture_interface.py      # Abstract interface for recognizers
â”‚  â”‚  â”œâ”€ paths.py                  # Asset path resolution (dev/packaged)
â”‚  â”‚  â”œâ”€ performance.py            # FPS & latency tracking
â”‚  â”‚  â”œâ”€ recognizer.py             # Legacy recognizer (compatibility)
â”‚  â”‚  â”œâ”€ recognizer_factory.py     # Factory + singleton for recognizers
â”‚  â”‚  â”œâ”€ recognizer_hybrid.py      # Hybrid: MediaPipe Hands + custom poses
â”‚  â”‚  â”œâ”€ recognizer_mediapipe.py   # MediaPipe Tasks API recognizer
â”‚  â”‚  â””â”€ ui_gesture_worker.py      # QThread worker for UI gestures
â”‚  â””â”€ ui/
â”‚     â”œâ”€ __init__.py
â”‚     â”œâ”€ qt_launcher.py            # PySide6 launcher window
â”‚     â””â”€ ui_draw.py                # Overlay drawing utilities
â”œâ”€ hooks/
â”‚  â””â”€ hook-mediapipe.py            # PyInstaller hook for MediaPipe
â”œâ”€ requirements.txt
â””â”€ README.md
```

---

## ğŸ”© How the system works

### Architecture overview
```
gesture_interface.py (Abstract base class)
        â†‘
        â”œâ”€â”€ recognizer_mediapipe.py (MediaPipe Tasks API)
        â””â”€â”€ recognizer_hybrid.py (MediaPipe Hands + custom poses)
                â†‘
        recognizer_factory.py (Factory + Singleton manager)
```

### Launcher flow
```
run_launcher.py
  â†“
qt_launcher.py (MainWindow)
  â†“
ui_gesture_worker.py (camera + UI gestures in QThread)
  â†“
recognizer_factory.py â†’ creates recognizer instance
  â†“
Closed_Fist â†’ move hover
Thumb_Up â†’ click button
```

### Game flow
```
User selects a game
  â†“
Browser opens game URL
  â†“
background_runner.py starts
  â†“
recognizer_factory.py â†’ MEDIAPIPE_TASKS or HYBRID_POSE
  â†“
controller.py presses keys via pynput
```

### Test mode
```
gesture_test.py
  â†“
recognizer_factory.py
  â†“
ui_draw.py overlays + skeleton
```

### Recognizer types
| Type | Description |
|------|-------------|
| `MEDIAPIPE_TASKS` | Uses pre-trained `gesture_recognizer.task` model. Best for static poses (Victory, ILoveYou, etc.) |
| `HYBRID_POSE` | Uses MediaPipe Hands with custom pose classification. Better for motion-based gestures (swipes) |

---

## ğŸ® Supported games

- ğŸš‡ **Subway Surfers (Poki)**  
  https://poki.com/en/g/subway-surfers

- ğŸƒ **Temple Run 2 (Poki)**  
  https://poki.com/en/g/temple-run-2

âš ï¸ **Important:** Keep the browser tab focused so key presses go to the game.

---

## âš™ï¸ Installation & running (development)

### 1ï¸âƒ£ Create virtual environment

**macOS**
```bash
python3 -m venv .venv
source .venv/bin/activate
```

**Windows (PowerShell)**
```powershell
python -m venv .venv
.venv\Scripts\activate
```

### 2ï¸âƒ£ Install dependencies
```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Run the launcher
```bash
python -m app.run_launcher
```

### 4ï¸âƒ£ Run test mode
```bash
python -m app.gesture_test
```

---

## ğŸ“¦ Packaging the app (PyInstaller)

### âš ï¸ Why a custom hook is required
MediaPipe Tasks uses compiled native libraries  
(`mediapipe.tasks.c`). PyInstaller does **not** bundle these automatically.

This project includes:
```
hooks/hook-mediapipe.py
```
to ensure all MediaPipe native binaries are included.

---

### ğŸ Build on macOS (.app)

```bash
pyinstaller --noconfirm --clean --windowed \
  --name "GestureGameController" \
  --additional-hooks-dir hooks \
  --add-data "app/assets/gesture_recognizer.task:app/assets" \
  app/run_launcher.py
```

Output:
```
dist/GestureGameController.app
```

If macOS blocks the app:
```bash
xattr -dr com.apple.quarantine dist/GestureGameController.app
```

---

### ğŸªŸ Build on Windows (.exe)

```powershell
pyinstaller --noconfirm --clean --windowed `
  --name "GestureGameController" `
  --additional-hooks-dir hooks `
  --add-data "app\assets\gesture_recognizer.task;app\assets" `
  app\run_launcher.py
```

Output:
```
dist\GestureGameController\GestureGameController.exe
```

---

## ğŸ§¯ Troubleshooting

### âŒ Game doesnâ€™t respond
- Browser tab not focused
- Camera permission not granted
- Poor lighting
- Hand too far from camera

### âŒ Gestures trigger multiple times
- Use edge-trigger logic (`IDLE â†’ ACTION`)
- Cooldown is already implemented in workers

### âŒ Packaging error:
`No module named mediapipe.tasks.c`
- Make sure you build with:
  ```
  --additional-hooks-dir hooks
  ```

---

## ğŸ“Œ Notes
This project covers the following features:
- MediaPipe Tasks API usage
- Gesture-driven UI navigation
- Background processing with Qt threads
- Cross-platform desktop packaging

